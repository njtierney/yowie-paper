---
title: "A Journey from Wild to Textbook Data to Reproducibly Refresh the Wages Data from the National Longitudinal Survey of Youth Database"
authors:
  - name: Dewi Amaliah
    thanks: ""
    department: Department of Econometrics and Business Statistics
    affiliation: Monash University
    location: Clayton, VIC 3800
    email: dlamaleeah@gmail.com
  - name: Dianne Cook
    department: Department of Econometrics and Business Statistics
    affiliation: Monash University
    location: Clayton, VIC 3800
    email: dicook@monash.edu
  - name: Emi Tanaka
    department: Department of Econometrics and Business Statistics
    affiliation: Monash University
    location: Clayton, VIC 3800
    email: emi.tanaka@monash.edu
  - name: Kate Hyde
    thanks: ""
    department: Department of Econometrics and Business Statistics
    affiliation: Monash University
    location: Clayton, VIC 3800
    email: "hyde.kate.a@gmail.com"
  - name: Nicholas Tierney
    thanks: ""
    department: ""
    affiliation: Telethon Kids Institute
    location: Nedlands, WA 6009
    email: "nicholas.tierney@gmail.com"
bibliography: references.bib
biblio-style: unsrt
#preamble: >
header-includes:
  - \usepackage{tcolorbox}
  - \usepackage{fontawesome}
  - \usepackage{color, colortbl}
output: 
  #rticles::arxiv_article:
    #keep_tex: false
  bookdown::pdf_book:
    base_format: rticles::arxiv_article
date: "24/02/2021"
always_allow_html: true
keywords: "Data cleaning; Data tidying; Reproducible workflow; Longitudinal data; NLSY79; Initial data analysis;"
abstract: > 
 Textbook data is essential for teaching statistics and data science methods because they are clean, allowing the instructor to  focus on methodology. Ideally textbook data sets are refreshed regularly, especially when they are subsets taken from an on-going data collection. It is also important to use contemporary data for teaching, to imbue the sense that the methodology is relevant today. This paper describes the trials and tribulations of refreshing a textbook data set on wages, extracted from the National Longitudinal Survey of Youth (NLSY79) in the early 1990s. The data is useful for teaching modeling and exploratory analysis of longitudinal data. Subsets of NLSY79, including the wages data, can be found in supplementary files from numerous textbooks and research articles. The NLSY79 database has been continuously updated through to 2018, so new records are available. Here we describe our journey to re-create the wages data, and document the process so that the data can be regularly updated into the future. Our journey was difficult because the steps and decisions taken to get from the raw data to the wages textbook subset, have not been clearly articulated. We have been diligent to provide a reproducible workflow for others to follow, which also hopefully inspires more attempts at refreshing data for teaching. Three new data sets and the code to produce them are provided in the open source R package, called [CENSORED]. 
---

```{r censor, include = FALSE}
CENSOR <- TRUE
yowie <- ifelse(CENSOR, "\\texttt{[CENSORED]}", "\\texttt{yowie}")
yowie_repo <- ifelse(CENSOR, "CENSORED", "https://github.com/numbats/yowie")
yowie_pkgdown <- ifelse(CENSOR, "CENSORED", "https://github.com/numbats/yowie")
yowie_shiny <- ifelse(CENSOR, "CENSORED", "https://ebsmonash.shinyapps.io/yowie_app/")
censor_word <- function(word) ifelse(CENSOR, "CENSORED", word)
```


```{r setup, echo = FALSE, cache = FALSE, include = FALSE}
library(knitr)
opts_chunk$set(echo = FALSE, 
               warning = FALSE, 
               message = FALSE,
               cache = TRUE, 
               cache.path = "cache/",
               fig.retina = 2,
               fig.path = "figures/",
               comment = "#>",
               fig.align = 'center')
read_chunk(here::here("data-raw/data-preprocessing.R"))
read_chunk(here::here("data-raw/ida.R"))
read_chunk(here::here("data-raw/eda.R"))
```

```{r ref.label=c("load-pkgs", "load-pkgs2"), cache = FALSE}
```

```{r theme, eval = FALSE}
theme_set(theme_bw(base_size = 18) +
            theme(plot.background = element_rect(fill = 'transparent', colour = NA), axis.line.y = element_line(color = "black", linetype = "solid"),
                  plot.title.position = "plot",
                  plot.title = element_text(size = 24),
                  panel.background  = element_rect(fill = 'transparent', colour = NA),
                  legend.background = element_rect(fill = 'transparent', colour = NA),
                  legend.key        = element_rect(fill = 'transparent', colour = NA)
                  ))
```


# Introduction {#intro}

<!--
- how does this particular data relate to education
- textbook data, why is this important for education
- being able to refresh textbook data is important
- what can we learn about the data that is different what is usually taught
-->

Statistics and data science education relies on cleaned and simplified data, suitably called textbook data, for clear examples about how to apply different techniques. An example of this, is the wages data made public by @SingerJudithD2003Alda in their book, "Applied longitudinal data analysis",  which can be used to teach generalized linear models, in addition to hierarchical, mixed effects and multilevel models. The data records hourly wages of a sample of high school dropouts, from 1979-1994, along with the demographic variables, such as education and race, taken from the National Longitudinal Survey of Youth (NLSY79) [@nlsy79]. 

The story from modeling the data (and as reported by Singer and Willett) is that wages increase with the length of time in the workforce, higher level of education leads to higher wages, and that race makes a difference, on average. An exploratory analysis reveals, however, that the individual experience varies a great deal from the overall average. Some individuals experience a decline in wages the longer they are in the workforce, and many experience volatility in their wages. The wages data was used to illustrate exploratory longitudinal data analysis in @ilk2004, and was further developed into a case study for use in the teaching of exploratory data analysis at `r censor_word("Iowa State University")`. 

<!--The story from modeling the data (and as reported by Singer and Willett) is that wages increase with the length of time in the workforce, higher level of education leads to higher wages, and that race makes a difference, on average. An exploratory analysis reveals however that the individual experience varies a great deal from the overall average. Some individuals experience a decline in wages the longer they are in the workforce, and many experience volatility in their wages. [DA: It seems that this paragraph is repetion form the previous paragraph.]-->

This disparity between the average and the individual is a part of statistics, as a discipline, that require more attention. This particular data set is a prime example of discussing this disparity. Textbook data sets have longevity if there is a unresolved mystery. The iris data [@iris-data] is a prime example. It has withstood the test of time because the three species cannot be perfectly classified, and so it continues to challenge researchers and instructors to do better in the analysis. (A side note: the iris data is best replaced today with the penguins data [@penguins-data], which has similar qualities, is new and does not suffer from a connection with eugenics [@notiris]. We argue that the wages data is in this class of textbook data, too, because it presents a challenge for longitudinal data analysis: how can we better summarize and explain the individual experience? 

For the field of statistics, and data science by association, it is increasingly important to reach the individual. One might describe this as a divergence of purpose, statistics for public policy or statistics for the public. The two are not the same. As the world becomes more electronically connected combating misinformation and mitigating conspiracy theories require that statistics address the individual. For example, with the wages data, even though the message for public policy is that demographic profile is related to different wage patterns on average, the message for the individual is that you are more than your demographic. The majority of people in the study do not have a pattern that is similar to the average. If you have a bad experience, that your wages have declined over time, you are not alone, there are others like you, and more than you think. A similar tone is echoed occasionally in the public media, for example, an article published in the Sydney Morning Herald argues that there is no average Australian [@notaverage].

As a textbook data set though, the wages data is outdated. The most recent year in the data is 1994, 10 years prior to when @SingerJudithD2003Alda was published. Teachers of statistics need contemporary data sets to show how techniques are relevant for today's students. Using tired old textbook data sets can imbue a misconception that the field is not current.  The wages data is extracted from NSLY79, one of the best examples of open data, which is constantly being updated. It should be possible to continuously refresh the textbook data from the data repository. This paper describes our (non-glamorous) journey from open [@opendata] wild data to textbook data. 


<!-- 
"Open data" is data that is freely accessible, modifiable, and shareable by anyone for any purpose [@opendata]. This type of data can be useful as example data in statistical textbooks and for research purposes. However, open data is often referred to as what we might call "wild data" because it requires substantial cleaning and tidying to tame it into textbook shape. @HuebnerMariannePhD2016Asat emphasize that making the data cleaning process accountable and transparent is imperative and essential for the integrity of downstream statistical analyses and model building --> <!-- AE comment: It's unclear from context what is being referred to from the Huebner et al 2020 citation  [@HuebnerMarianne2020Haar]. --> 
<!-- Data cleaning can be considered to be a part of what is called "initial data analysis" (IDA) [@Chatfield1985TIEo]. In IDA one would also explore the data, especially to check if the data is consistent with assumptions required for modeling. This is also related to exploratory data analysis (EDA), coined by @tukey with a focus on learning from data. EDA can be considered to encompass IDA. @DasuTamraparni2003Edma say that data cleaning and exploration, without naming it as IDA, is a difficult task and consumes 80% of the data mining task. -->

<!-- Despite it's importance, this IDA stage is often undervalued and neglected [@Chatfield1985TIEo]. There are few research papers that document the data cleaning [@WickhamHadley2014TD]. Furthermore, the decisions made in this stage often go unreported in the sense that IDA is often performed in an unplanned and unstructured way and is only shared among restricted parties [@HuebnerMarianne2020Haar]. -->

This paper demonstrates the steps of cleaning data, including subjective decisions made on dealing with anomalies, and documents the process, as recommended by @HuebnerMariannePhD2016Asat. They emphasize that making the data cleaning process accountable and transparent is imperative and essential for the integrity of downstream statistical analyses and model building. Clean data often then goes through an "initial data analysis" (IDA) [@Chatfield1985TIEo], where one would summarize and scrutinize the data, especially to check if the data is consistent with assumptions required for modeling. This stage is related to exploratory data analysis (EDA), coined by @tukey with a focus on learning from data. EDA can be considered to encompass IDA. In practice, the three stages of cleaning, summarizing, and exploring are cyclical, that one often needs to do more cleaning after scrutinizing. @DasuTamraparni2003Edma say that data cleaning and exploration is a difficult task and typically consumes a large percentage of the time spent in analyzing data.

Our approach to cleaning builds heavily on the `tidyverse` approach [@tidyverse]. The data is first organized into "tidy data" [@WickhamHadley2014TD] and then further wrangled using a step-wise piping with split-apply-combine strategy for mutating new variables [@plyr]. Tidy data shouldn't be confused with "tame data" which @tamedata coined to refer to textbook data sets suitable for teaching, particularly teaching statistics. The resulting (tame) data is provided in a new R package called `r yowie` which includes the code so that the process is reproducible, and could be used to further refresh the data as new records are made available in the NLSY79 database. 

This paper is structured in the following way. Section \@ref(database) describes the NLSY79 data source. Section \@ref(cleaning) presents the steps of cleaning the data, including getting and tidying the data from the NLSY79 and IDA to find and repair anomalies. Our final subset is compared to the old textbook subset in Section \@ref(compare). Finally, Section \@ref(summary) summarizes the contribution and makes recommendations for the NLSY79 data curators. 

# The NLSY79 {#database}

@SingerJudithD2003Alda used the wages and other variables of high school dropouts from the NLSY79 data as an example data set to illustrate longitudinal data modeling of wages on workforce experience, with covariates education and race. This data has been playing an important role in research in various disciplines, including but not limited to economics, sociology, education, public policy, and public health for more than a quarter of the century [@MichaelRPergamit2001DWTN]. In addition, this is considered a carefully designed longitudinal survey with high retention rates, making it suitable for life course research [@MichaelRPergamit2001DWTN; @eliznlsy]. According to @eliznlsy, thousands of articles, and hundreds of book chapters and monographs have utilized this data. Moreover, the NLSY79 is considered the most widely used and most important cohort in the survey data [@MichaelRPergamit2001DWTN].  <!--AE comment: For example, I would like more discussion about the textbook selected as the exemplar. It sounds like this dataset is used in many books, why choose that one? The text should include the name of the book, so readers do not need to flip to the citations in order to learn what it was. From the name, I am guessing that the book focuses heavily on this dataset, which is why it makes sense to reproduce their subset. Be explicit about this.-->

Our aim is to refresh the wages textbook data and append it with data from 1994 through to the latest data reported in 2018, a purpose that is consistent with @grimshaw's statistics education goal of embracing authentic data experiences. Here, we investigate the process of getting from the raw NLSY79 data to a textbook data set as similar as possible to that provided by @SingerJudithD2003Alda. We should also note that race is a variable in the original data set, and for compatibility it is also provided with the refreshed data, for the *purposes of studying racism, not race* [@racismnotrace]. There are a number of data sets provided by @SingerJudithD2003Alda and we focus only on this one because it has captivated our attention for a number of years. We use it in our own teaching of longitudinal data analysis and would very much like to use data since 1994. <!--However, we cannot create the exact same data set as published in their book since we do not have the information of what age threshold they used to determine the high school dropouts.-->

## Database

The NLSY79 is a longitudinal survey administered by the U.S Bureau of Labor Statistics that follows the lives of a sample of American youth born between 1957-1964 [@nlsy79]. The cohort originally included 12,686 respondents aged 14-22 when first interviewed in 1979. For a variety of reasons, some structural, the number of respondents dropped to 9,964 after 1990. <!--It is comprised of people sampled because they were black, hispanic, economically disadvantaged non-black non-hispanics, and youth in the military. In 1984 and 1990, two sub-samples were dropped from the interview; the dropped subjects were the 1,079 members of the military sample and 1,643 members who represents economically disadvantaged people, but were not black nor hispanics, respectively. These subsamples were dropped because they were no longer eligible for interviews [@nlsy79]. Hence 9,964 respondents remain in the eligible samples.--> The surveys were conducted annually from 1979 to 1994 and biennially thereafter. Data are currently available from Round 1 (1979 survey year) to Round 28 (2018 survey year).

Although the main focus area of the NLSY is labor and employment, the NLSY also covers several other topics, including education, training, achievement, household, geography, dating, marriage, cohabitation, sexual activity, pregnancy, fertility, children, income, assets, health, attitudes and expectations, crime, and substance use. 

There are two ways to conduct the interview of the NLSY79, which are face-to-face or by telephone interviews. In recent survey years, more than 90 percent of respondents were interviewed by telephone [@eliznlsy].

## Target data {#target}


The NLSY79 data used in @SingerJudithD2003Alda contains the longitudinal records of male high school dropouts who first participated in the study at age 14-17 years from 1979 through to 1994. This dataset contains several variables as follows: 

1. ID: the respondents' ID. 
2. EXPER: temporal scale, i.e., the length of time (years) in the workforce, starting on the respondents' first day at work.
3. LNW: natural logarithm of wages, adjusted with 1990's inflation rate. 
4. BLACK: binary variable, 1 indicates black and 0 otherwise. 
5. HISPANIC: binary variable, 1 indicates hispanic and 0 otherwise. 
6. HGC: the highest grade completed.
7. UERATE: unemployment rate of the year of survey. When missing, the variable is set to be 7.875 (the average rate).

We refresh this data by re-creating the full data with records from survey years 1979 through to 2018 (the most recent year published). We also modify some variables. For example, use a single categorical race variable instead of the two binary race variables.  We also plan to include additional variables, some for the purpose of providing more options for data exploration in teaching examples: year of the survey, age of individual in 1979, whether the individual completed high school with diploma or with a graduate equivalency degree (GED), the highest grade completed in the corresponding year of survey, the number of jobs that the individual had in the corresponding year of survey, total number of hours the individual usually works per week, the year when individual started to work, and the number of years the individual worked. We do not attempt to re-create the unemployment rate variable.

The plan is to create three datasets as follows:

1. The wages data of the whole NLSY79 cohort, including females.
2. A separate table of the demographic data of the whole NLSY79 cohort.
3. The wages data of the high school dropouts, which is closest to a refreshed version of @SingerJudithD2003Alda's data. 

<!-- Since no specific criteria on high school dropouts was defined
in @SingerJudithD2003Alda, we define high school dropouts as respondents who only completed either 9th to 11th grade, or who completed 12th when their age is at least 19 years old (meaning that the individual may have dropped out of high school but returned at a later time to complete high school education). XXX This should probably go further down in the flow. -->

# Data cleaning {#cleaning}

@LooMarkvander2018Sdcw in the context of official statistics describe the "statistical value chain" which includes various production stages of the data cleaning process as raw data (data in the initial that it arrives), input data (data organised with correct type and identified variables) and valid data (data that has been cleaned and more accurately represents the intent of variables). What we have colorfully named as wild data can be considered to be raw data, and valid data could be considered to be textbook data, in the above statistical value chain. In this section, we outline the steps to download the raw data (Section \@ref(getdata)) and then tidy the raw data into input data, specifically for the demographic variables (Section \@ref(tidydemog)) and the employment variables (Section \@ref(tidyemp)), so that the resulting input data can be used downstream for validating the data as described in Section \@ref(ida).


## Getting the data {#getdata}


The NLSY79 data contains a large number of variables but for our purposes the scope required is limited to demographic profiles, wages data, and work experience. More specifically, we went to the NLSY79 database website at \url{https://www.nlsinfo.org/content/cohorts/nlsy79/get-data}, clicked on the direct link to NSLY79 data and navigated as described in Figure \ref{fig:source-nav}.

\begin{figure}[t]

\begin{tcolorbox}[title = Navigating the data source]
\faDatabase\ NLSY79 (\url{https://www.nlsinfo.org/investigator/pages/search?s=NLSY79})\\
\vspace{1mm}
\faCheck\ The CASEID will be always be selected.  \\
\vspace{1mm}
\faCheck\ The 3 recommended demographic variable (sample ID, race and sex) were selected.  \\
\vspace{1mm}
For the remaining variables, we went to the "Variable Search" tab and select variables as follows
\begin{itemize}
\item[$\triangleright$] Education, Training and Achievement Scores
\begin{itemize}
\item[$\triangleright$] Education $\triangleright$ Summary measures $\triangleright$ All schools $\triangleright$ By year
\begin{itemize}
\item[$\triangleright$] Highest grade completed
\begin{itemize}
\item[\faCheck] All 80 variables in Highest grade completed were selected.
\end{itemize}
\end{itemize}
\begin{itemize}
\item[$\triangleright$] Dates of diploma or degree
\begin{itemize}
\item[\faCheck] All variables named Q3-8A were selected.
\end{itemize}
\end{itemize}
\end{itemize}
\item[$\triangleright$] Employment
\begin{itemize}
\item[$\triangleright$] Summary measures $\triangleright$ By job
\begin{itemize}
\item[$\triangleright$] Hours worked  
\begin{itemize}
\item[\faCheck] All 447 primary variables in Hours worked were selected.
\end{itemize}
\item[$\triangleright$] Hourly wages
\begin{itemize}
\item[\faCheck] All 156 variables in Hourly wages were selected.
\end{itemize}
\end{itemize}
\end{itemize}
\begin{itemize}
\item[$\triangleright$] Summary measures $\triangleright$ Since date of last interview $\triangleright$ Weeks worked
\begin{itemize}
\item[\faCheck] All 28 variables in Weeks worked were selected.
\end{itemize}
\end{itemize}
\begin{itemize}
\item[$\triangleright$] Employer Roster $\triangleright$ Job dates $\triangleright$ Original start date
\begin{itemize}
\item[\faCheck] Only selected the start date (Year) for the first job (E00101.02)
\end{itemize}
\end{itemize}
\item[$\triangleright$] Household, Geography \& Demographics
\begin{itemize}
\item[$\triangleright$] Demographics $\triangleright$ Basic demographics $\triangleright$ Date of birth
\begin{itemize}
\item[\faCheck] All 4 variables in Date of birth were selected. 
\end{itemize}
\end{itemize}
\end{itemize}
\begin{itemize}
\item[\faCloudDownload] To download all 742 variables selected, we then navigate to the tab "Save / Download" then select the tab "Advanced Download". We select the R Source code and comma-delimited datafile of selected variables with Reference Number as column headers. We name the filename "NLSY79" and press the download button. There are also options to get control or dictionary files for SAS, SPSS and STATA. 
\end{itemize}
\end{tcolorbox}
\caption{Documented steps taken to select variables of interest and download the raw data.\label{fig:source-nav}}
\end{figure}
      
The downloaded data set comes as a zip file, containing the following set of files:

- `NLSY79.csv`: comma separated value format of the response data,
- `NLSY79.dat`: alternative text format of the response data,
- `NLSY79.NLSY79`: tagset of variables that can be uploaded to the website to recreate the data set, and
- `NLSY79.R`: R script for reading the data into R and converting the variables' names and label into something more sensible. 

We alter only the file path in `NLSY79.R` and run the script without any other alteration. This results in an initial processing of the raw data into two data sets,  `categories_qnames` (where the observations are stored in categorical/interval values) and `new_data_qnames` (the observations are stored in integer form). 

```{r raw-data}
```

According to @WickhamHadley2014TD, tidy data sets comply with three rules: (i) each variable forms a column, (ii) each observation forms a row, and (iii) each type of observational unit forms a table. The raw data, `new_data_qnames`, does not comply with these rules as it is organised such that each row corresponds to an individual. As respondents can have multiple jobs at specific years, the column names, such as `HRP1_1979`, `HRP2_1979`, `HRP1_1980` and `HRP2_1980`, contain the information about the job number up to 5 (`HRP1` = job 1, `HRP2` = job 2) and the year. The raw data consequently has a large number of columns (`r ncol(new_data_qnames)` to be specific). The values in the cell under the variables that begin with `HRP` correspond to the hourly wage in dollars. A glimpse of this data shows:

```{r untidy-data}
```

Thus we re-arrange and wrangle the data into tidy data form, columns corresponding to individual ID, year, job number, wage in dollars and the demographic variables. This is done using the `tidyverse` suite of packages [@tidyverse]: `tidyr` [@tidyr] to pivot the data into long form, with `dplyr` [@dplyr] and `stringr` [@stringr] to mutate new variables from the downloaded data from the database, and code levels of factors by text wrangling. The long form of the data makes it possible to do these data transformations efficiently, and it is an intermediate step towards the final target data. The code for tidying the data are demonstrated at \url{`r yowie_pkgdown`/articles/raw-to-input-data.html} but also described in the subsequent subsections.

<!-- required by making use of the `tidyverse` suite of packages [@tidyverse], which include the main set of packages needed, namely `tidyr` [@tidyr], `dplyr` [@dplyr], and `stringr` [@stringr]. The tidy data form, where we have a variable that indicates the individual ID, year, job number, wage in dollars and demographic variables, is important for downstream analysis, such as visualisation and modelling that will be performed later. 


[REMOVE] Unfortunately, the `new_data_qnames` did not meet these requirements in the way that data for each year and job for the same respondent is stored as one variable. Hence, the data contains a huge number of columns (686 columns). The example of the untidy data set is displayed in Table \ref{tab:untidy-data}. The table intended to display the hourly rate of each respondent by job (HRP1 to HRP5) and by year (1979 and 1980). The table implies that the column headers are values of the year and job, not variable names. Consequently, the data should be tidied and wrangled first to extract the demographic and employment variables we want to put in the final data set. We mainly used `tidyr` [@tidyr], `dplyr` [@dplyr], and `stringr` [@stringr] to do this job.-->

### Tidying demographic variables {#tidydemog}

In our final target data, we wish to include the demographic variables with variable names specified in brackets: gender (`gender`), race (`race`), age (`age_1979`), highest grade completed reported in each round of survey (`grade`), highest grade completed ever reported (`hgc`), highest grade completed in terms of years, e.g. 9th grade = 9, 3rd year college = 15, (`hgc_i`), and whether the graduate equivalency diploma is obtained (`ged`).

It is worth noting that `gender` comes from a variable called `sex` in the database. We use the term `gender` as the reports about the data on various pages in the website more commnly use `gender`. Gender, as provided in the data, is self-reported and only has two categories, "male" and "female". The interchangeable use of these terms reflects that gender and sex are sometimes regarded as similar in surveys, although they are not. Measuring gender as a binary variable has the potential to fail to capture people who do not identify themselves as either male or female or people whose gender does not align with their sex classification [@kennedy2020using]. From a statistical perspective, this sometimes difficult the adjustment of survey statistics to the population when gender is measured, for example, with three categories, and the census measured it with only two categories and used the term sex [@kennedy2020using]. Hence, for modern societal studies, it is highly recommended to separate sex and gender in the survey question and provide more options to respond to questions on gender. This discourse should also be emphasized in teaching that using these two variables should be accompanied by special attention. Similar this also relates to race, as reported in the database. When doing an analysis with this variable, one should keep in mind that the purpose is to study racism rather than race. 

The raw data, `new_data_qnames`, contains the variables `Q1-3_A~Y_1979` and `Q1-3_A~Y_1981` which records two versions of the birth year of the respondent; this is also the case for the record of birth month (`Q1-3_A~M_1979` and `Q1-3_A~M_1981`). The record contains two versions of birth year and birth month as the survey recorded this in 1979 and 1981. We checked for consistency between the two versions and found no discrepancy where the responses were recorded in both 1979 and 1981. The age was then calculated using the birth year. 


```{r dob-tidy}
```
```{r demog-tidy}
```
```{r demog-ed}
```

<!--AE comment: I was confused by the following section: “We choose to use this revised May data because it seemed to have less missing and presumably has been checked. However, there is no revised May data for 2012, 2014, 2016, and 2018, thus, we use the ordinary May data for these years.” I was assuming the data was collected on a yearly basis, but this section suggests it was collected each month. Please clarify somewhere in the paper. 
-->

The refreshed dataset has two types of highest grade completed. The first one is the highest grade completed ever reported in the database (`hgc` and `hgc_i`, for the factor and integer type, respectively). For each ID, there is only one value of `hgc` and `hgc_i`. This variable is obtained from `new_data_qnames` with name `HGC_EVER_XRND` and stored in year unit (e.g., 10, 11, 12, 13, and so on), we only rename the column name to be `hgc_i` and recode it so we have the factor data type (e.g., 10th grade, 11th grade, and so on). 

The second one is the highest grade completed corresponds to value  reported in each round of the survey (`grade`), meaning that the value can change. We decide to include this variable in the refreshed dataset to enrich the analysis possibly done with the data, for example if one would like to explore how the changes of highest grade completed in individuals affecting their wages. The highest grade completed are recorded in `new_data_qnames` as variables beginning with `Q3-4` and `HGC` with suffix of the year it was recorded. In addition the variables beginning with `HGCREV` contain the revised data. We choose to use this revised data because it seemed to have less missing and presumably has been checked. However, there is no revised data for 2012, 2014, 2016, and 2018, thus, we use the ordinary data for these years. <!--We also check the consistency between `hgc_i` and `grade`. Some problematic observations were found, for example, `grade` value is greater than `hgc_i`. We then fix this problem by replacing those `grade` that is greater than its `hgc_i`. -->

The next step is tidying to obtain `ged`. Along with `hgc`, `ged` is used to subset the data to the high school dropouts as in the original data. The graduate equivalency status is saved as variable started with "Q3-8A" followed by the year of the survey. Thus, we only separate the year and the GED status. Although there GED status is asked in each round of the survey, we only retain the latest status of one's GED.  

```{r tidy-grade}
```

```{r tidy-hgc}
```

Finally, we get all of the demographic profiles of the NLSY79 cohort. We then save this data as `demog_nlsy79`.

```{r full-demog}
```


### Tidying employment variables {#tidyemp}

Our target variables for the employment are to obtain respondent's mean hourly wage (`wage`), the number of jobs (`njobs`), the total hours of work per week (`hours`) for each survey year, the year when individual starting to work (`stwork`), the length of time (years) in workforce (`yr_wforce`), and work experience measured as the number of years worked (`exp`). As the data only reports up to 5 jobs for each respondent, the maximum number of jobs is capped at 5. 

From 1979 to 1987, `new_data_qnames` only contains one version of hours worked per week for each job (in the variables with names starting with `QES-52A`). From 1988 onward, we selected the total hours worked per week, including hours working from home (`QES-52D`). However, in 1993, this variable was missing for the first and last job so we selected to use `QES-52A` instead. In addition, 2008 only had jobs 1-4 for the `QES-52D` variable, so we use only these.

```{r tidy-hours}
```

The hourly wages are in the variables beginning with `HRP` in `new_data_qnames`. As a respondent may have multiple jobs, the `mean_hourly_wage` is computed as a weighted average of the hourly wage for each job with the number of hours worked for each job as weights (provided that the information on number of hours is available); if number of hours worked for any job is missing, then the `mean_hourly_wage` is computed as a simple average of all available hourly wages. Prior to computing the mean hourly wage, we undertook a number of steps to treat unusual observations as described below:

* If the hourly rate is recorded as 0, we set wage as missing.
* If the total hours of worked for the corresponding job is greater than 84 hours, we set the wage and hour worked as missing. 

The number of jobs (`number_of_jobs`) for each respondent per year is computed from the number of non-missing values of hourly wage. In other words, even if the information of hours worked exists for a particular observation, we do not tally when the hourly wage is missing.

```{r tidy-rate}
```

```{r tidy-start-work}
```

```{r tidy-work-experience}
```

```{r tidy-rate-hour}
```

```{r tidy-nojob}
```

For `stwork` variable,  we only rename the column names from `new_data_qnames`. This variable is then used to calculate the next variable, `yr_wforce` for each survey round, which is the year of survey (`year`) minus the year of individual start working (`stwork`). Finally, `exp` variable is derived from the number of weeks worked since the last interview indicated as variable started with `WKSWK` in `new_data_qnames`. To obtain the work experience since 1979, we calculate the cumulative value. As the measurement unit is in week, we convert this to year.

The employment and demographic variables are then joined. These data are further filtered to the cohort who participated in at least three rounds in the survey, the minimum observation recommended for longitudinal data in @SingerJudithD2003Alda. We also opt to restrict the minimum number of observations so that the data can be used to demonstrate within-person variation when it is used to teach longitudinal data. However, it is worth noting that the original data does not restrict the number of observation for each individual, i.e, there are individuals with only one and two observations. 

Finally, we save the resultant wage data on this cohort as `wages`. Note that we save `grade` variable in this dataset, instead of `demog_nlsy79` dataset because it is a longitudinal variable, while `demog_nlsy79` is cross-sectional dataset reflecting the state of individuals corresponding to the most recent round of the survey. 

```{r wages-demog-hs}
```

## Calculated variables: work experience

Work experience is one of the most important variables in @SingerJudithD2003Alda as it indicates time, and makes longitudinal analysis possible. It is desirable to calculate this rather than using the survey year for time because it more accurately reflects a person's time in the workforce. Thus, in the spirit of refreshing the data to the newest round of the survey, this variable needs to be calculated from other variables provided. It is not straightforward. We start with the definition of experience in @SingerJudithD2003Alda. 

Experience is years after entering the labor force. It represents the difference between the day an individual enters the labor force (`EMPLOYERS_ALL_STARTDATE_ORIGINAL.01~Y_XRND` in the database) relative to the date of the survey, which we call `yr_wforce`. However, using this calculation produced numbers which don't quite match with the original data. 

Reading the section titled ["Topical Guide to the Data"](https://www.nlsinfo.org/content/cohorts/nlsy79/topical-guide/employment/work-experience) in the guide, suggests that it should be calculated based on the variable "number of weeks worked since last interview". This would remove periods of unemployment which makes sense when measuring experience while actually working. Since it is only measured since the last interview, this needs to be cumulated for each survey year. This produced results more similar to the original data (as discussed futher in Section \@ref(takeaways)).

<!--It is conceptually motivated by the variables available in the original data and it also illustrates how one would create a new variable from the information provided by the database, a variable that is more useful than those provided.-->

## Initial data analysis {#ida}

According to @HuebnerMariannePhD2016Asat, initial data analysis (IDA) is the step of inspecting and screening the data after collection to ensure that the data is clean, valid, and ready to be deployed in the later analyses. This is supported by @Chatfield1985TIEo who argues that the two main objectives of IDA are data description, which is to assess the structure and the quality of the data, and model formulation without any formal statistical inference. 

In this paper, we conduct an IDA or a preliminary data analysis to assess the validity of the variable values in the cohort of data that the NLSY provides. <!-- AE comments: This comes as a surprise to the reader. What anomaly? The wage anomalies should be mentioned in the introduction so as not to be a surprise at this point in the manuscript.
 --> A first step is validating numerical summaries of the raw data are the same as reported by NLSY79. This is followed with graphical summaries using methods available in `ggplot2` [@ggplot2] and `brolgar` [@brolgar]. 

The respondents' ages ranged from 12 to 22 when first interviewed in 1979. Hence, we validate whether all of the respondents were in this range in the data we extracted. Additionally, the [NLSY](https://www.nlsinfo.org/content/cohorts/nlsy79/intro-to-the-sample/nlsy79-sample-introduction) also provides the number of the survey cohort by their gender (6,403 males and 6,283 females) and race (7,510 Non-Black/Non-Hispanic; 3,174 Black; 2,002 Hispanic). To validate this, we used the `demog_nlsy79`, i.e., the data with the survey years 1979 sample. Tables \ref{tab:age-table} and \ref{tab:gender-race-table} suggest that the demographic data we had is consistent with the sample information in the database.



```{r sample-plot, echo = FALSE, fig.cap="Longitudinal profiles of wages for a random sample of 36 individuals in the pre-cleaned data. There is considerable variation in wages. Some individuals  (2799, 11041, 11146) are only measured for a short period. Some individuals (8296, 9962) possibly have errors in wages in some years, because of the extreme fluctuation.", fig.height=8, fig.width=10, out.width="100%"}
```

<!--AE comment: With the IDA about wage data, I would appreciate a bit more context. Why sample 36 observations? I am not a longitudinal data expert, so I was a bit surprised when I flipped to the plot and found it to be small-multiple time series, although upon further consideration it makes sense. In that section it would be good to describe what the figure shows in a bit more detail. Perhaps “We randomly sample 36 respondents from the data, and plot their average wage as a time series. Looking at the patterns over time, we see a lot of variability in wages. For example, the people shown in panels 5, 7, and 11 have [explain what is interesting here, again I’m not an expert].” The next sentence here, “Some have had flat wages for years but had a sudden increase in one particular year, then it gone down again, while the others experienced an upsurge in their wage, for instance, the IDs in panel 9.” does not seem to provide much additional information. What were you looking for here? Overall trends over time, increasing/decreasing? Any places where one year’s wage looked really different?-->


In the next step, we explore the mean hourly wage data of samples of individuals. The purpose is to examine the common patterns and check the quality. A random sample of 36 individuals is chosen (using the `sample_n_keys` function in `brolgar`). Their longitudinal profiles are plotted, faceted by `id` and using free $y$ scales, so that the individual patterns can be examined (Figure \ref{fig:sample-plot}).<!--AE comment: "It" implies... Please specify what "it" refers to. This could be done by adding onto the first sentence... "as shown in Figure 2, which shows that some respondents have high variability in wages, particularly 5, 7, and 11." However, 7 and 11 don't seem to have particularly high variability, especially when compared to 18. This whole paragraph needs to be fixed/updated.--> There is a lot of variability from one individual to another, and substantial fluctuation in wages at different times for most individuals. Some individuals  (2799, 11041, 11146) are only measured for a short period. Some individuals (8296, 9962) possibly have errors in wages in some years, because of the extreme fluctuation. These need to be inspected more closely. 

 <!--AE comment: Not panel 9 --> the IDs in panel 9. 
<!--I think there is a narrative step missing here, which is that looking at those samples led you to look at plots that show values for the wage variable over all participants and all years. The phrase “the summary plots” was not enough description for me to know what to expect when I flipped to Figure 3. Please be explicit about what the three plots were, why they were made, and what you were looking for. I think there is another narrative step missing about Figure 3C, which is that after you saw there were outliers you tried to identify which respondents had the extreme values. Again, please spell this out in the text. When you return to the plots for the entire dataset in Figure 5, please make parallel comments. -->

Figure \ref{fig:feature-plot}s shows an alternative way to check the data quality. Plot (A) is the spagetti plot where all profiles are shown, and it can be seen that there are unbelievably high wage values (up to $60,000/hour) for some individuals mostly around 1990. Plot (B) shows side-by-side boxplots of the three number summaries (minimum, median and maximum) for all individuals. This tells us that there are a number of individuals with unbelievably high maximum wages. Plot (C) shows the profile for an individual, with not such a high maximum wage but still indicates a problem: their wages are consistently low except for one year where they earned close to $1200/hour. This does not seem to be reasonable, and leads us to use a procedure to detect and fix these temporal anomalies.

```{r age-table}
```

<!--AE comment: Table 2 seems to have more precision than is necessary. Certainly 100% does not need to be reported as 100.00%, and probably all the percentages could be rounded to the nearest 1 percent. The caption could explain this, as there might be some rounding errors. -->

```{r gender-race-table}
```


```{r summarytable, eval=FALSE}
```

<!--AE comment: Figure 2’s caption should include something about how that data is the raw values from the survey, before inputing anomalous values so the figure and caption can stand alone.-->

<!--For both Figure 3 and Figure 5, I would prefer the letter label before the description, but that’s a matter of personal preference.-->

```{r feature-plot, fig.cap = "Summary plots to check the data after the tidying stage: (A) longitudinal profiles of wages for all individuals 1979-2018, (B) boxplots of minimum, median, and maximum wages of each individual, (C) and one individual (id=39) with an unusual wage relative to their years of data. It reveals that some values of hourly wages are unbelievable, and some individuals have extemely unusual wages in some years. Accordingly, more cleaning is necessary to treat these extreme values.", fig.width=10, fig.height=4, out.width="100%", cache = FALSE}
```

```{r high-wages}
```

```{r high-wages, fig.cap= "6 out of 45 IDs with extremely high mean hourly wage. Most of the IDs only have one point of high wage.", eval=FALSE}
```

<!--The next paragraph, which begins “The anomalies are also found” should perhaps be “Similar anomalies were found.” Was it the same respondents with the extremely high wages that showed extremely high number of hours of work? I suspect not, but please be explicit.-->
Extremely high values were also found in the total hours of work, where some observations reported as having worked for 420 hours a week in total. According to @MichaelRPergamit2001DWTN, one of the flaws of the NLSY79 employment data is that the NLSY79 collects the information of the working hours since the last interview. Thus, it might be challenging for the respondents to track the within-job hours' changes between survey years, especially for the respondents with fluctuating working hours or seasonal jobs. It even has been more challenging since 1994, after which respondents were only surveyed every other year and thus had to recall two full years’ job history. This shortcoming might also contribute to the fluctuation of one's wages data. 


## Replacing extreme values {#censor}

<!--AE comment: Section 3.2.1 begins “As part of the IDA, which is the model formulation, we build a robust linear regression model to treat the extreme values in the data.” This could use clarification. In 3.2, you said that part of IDA is “ model formulation without any formal statistical inference.” To me, that sounds like using modeling as a descriptive technique, and it’s something I would consider to be more a part of EDA. But then in 3.2.1, while it is perhaps not using modeling in an inferential way, the model is being used for more than just description. I might rephrase the first sentence as follows: “In order to treat the extreme values in the data, we built a robust linear regression model.” -->
<!--AE comment: Awkward sentence. "which is the model formulation"?--> A robust linear regression model using the `rlm` function from `MASS` package [@mass] is used to treat the extreme values in the data. The robustness weight is used to determine if a value should be replaced with the fitted value from the model. This is constructed for each ID utilizing the `nest` and `map` function from `tidyr` [@tidyr] and `purrr` [@purrr], respectively. An alternative approach would be a robust linear mixed model using `robustlmm` [@KollerManuel2016rARP]. However, when we tested this, the fit failed to convergence. <!--I would pull the tidy and purrr citations to the end of the sentence to make it read more smoothly-->The full code for this is shown at \url{`r yowie_pkgdown`/articles/input-to-valid-data.html} but also described in detail next.

The `mean_hourly_wage` and `year` are set as the dependent and predictor, respectively. Furthermore, we use iteratively reweighted least squares with Huber weighting, where the observation with a slight residual gets a weight of 1, while the larger the residual, the smaller the weight (less than 1) [@rlm]. <!--AE comment: “However, the challenging part of detecting the anomaly using the robustness weight is determining the weight threshold in which the observations are considered outliers.” I don’t think this sentence needs a “However” and probably should say “past which” rather than “in which”-->The challenging part of detecting the anomaly using the robustness weight is determining the weight threshold in which the observations are considered outliers. It should be noted that it is not possible to determine if all outliers are errors, and it might be that an individual had abnormally high wages at a particular time. 

<!--AE comment: At the bottom of page 11, where you describe the model formation, more detail would be appreciated. You are modeling the mean hourly wage based on year. Why? Is this standard practice for robust linear regression? What is a “slight” residual? Is it defined based on absolute magnitude, or standard deviations, or something else? Later, you say “To minimize the risk of mistakenly identifying an outlier as an “erroneous outlier”.” Is an erroneous outlier a technical term? If not, I think you are trying not to identify erroneous outliers, not mistakenly identifying outliers as erroneous outliers (that’s a double negative). The value of 0.12 feels very specific and out of place in a paper that has had few numerals. Is this a number an expert in RLR would be able to understand? Again, is that a raw value? Is it a standard deviation? Is there literature about how to choose a threshold? Overall, the sentence “We find that 0.12 is the most reasonable value to be the threshold to minimize that drawback’s risk because it still captures the sensible spikes in the data.” is vague and should be expanded upon. What is “that drawback’s risk”? What are “the sensible spikes in the data?” Be more explicit.-->

To explore the risk of being overly vigorous in labeling observations as outliers, some testing of threshold value was done. Samples of individuals were examined under the different thresholds, with an eye to smoothness of the profiles. Overly smooth profiles would indicate that the replacement of values was too severe, resulting in the removing the very interesting volatility of wages seen in many individuals. A threshold of 0.12 was chosen, that struck a balance between maintaining the natural variability of the wages with minimizing implausible values.
Using this threshold, we impute the observations whose weights are less than 0.12 with the models' predicted value. We then flag those observations in a new variable called `is_pred`, so that this change can be monitored in the downstream analyses. 


```{r rlm, eval=FALSE}
```

Figure \ref{fig:compare-plot} shows the mean hourly wage before and after the extreme values are replaced. The plot shows that fluctuations in wages remain but the large spikes (in this sample individuals 8296, 9962) which are considered implausible are replaced. 


```{r compare-data}
```


```{r compare-plot, fig.cap="Comparison between the original (black dots) and the corrected (solid grey) mean hourly wage for same sample of individuals as shown in Figure 2. A robust linear model prediction was used to identify and correct mean hourly wages value. The extreme spikes, corresponding to implausible wages, have been replaced with values more similar to wages in neighboring years for individuals 8296 and 9962, but otherwise the profiles have not changed.", fig.height=8, fig.width=10, out.width="90%"}
```

Figure \ref{fig:fixed-feature-plot} shows the summary statistics after removing extremes. The highest wage overall is now around $1000. Plot (A) shows a more reasonable spagetti plot, where there are some profiles with high wages, but most profiles have wages under $300, and there is a steady increase in wages with years. Plot (B) shows that there are still a small number of individuals with high maximum wages.  Plot (C) shows the profile for ID=39, after imputing the extreme value. The wages for this individual increase over the years, and do fluctuate some between 1900 and 2005. 
<!--AE comment: What does “It implies that the fluctuation can still be observed in the data after the treatment.” mean? I suspect this sentence should be replaced with something along the lines of “The figure shows that fluctuations in wages still exist even in the imputed data.”-->



```{r fixed-feature-plot, fig.cap = "Re-make of the summary plots of the fully processed data suggest that it is now in a reasonable state: (A) longitudinal profiles of wages for all individuals 1979-2018, (B) boxplots of minimum, median, (C) and maximum wages of each individual, and one individual with an unusual wage relative to their years of data. ", fig.width=10, fig.height=4, out.width="100%", cache = FALSE}
```


```{r save-data}
```

```{r nrow}
```


## Recap 

There are many steps and decisions made to go from raw to input to valid data. Figure \ref{fig:flow-chart-blind} summarizes these in order to create a refreshed wages data set. 

<!--To summarise, the  a workflow from getting the data from the NSLY79 database until a ready-analysed data. Referring to @LooMarkvander2018Sdcw, this section shows  part of statistical value chain, which is data cleaning from raw, input, and valid data. The raw demographic and employment data from the database are not in a tidy format. Hence, we perform data wrangling to get the input data. We inspect the input data to find eligible observations to the target data. One of the target data is wages data of respondents who completed up to 12th grade and participated at least in 5 rounds of survey. This needs us to join the extracted demographic and employment data. 

Further, using IDA, we inspect on the existence of anomalies/extreme values in the data using the weight from robust linear model. We then replace these extreme values using their predicted value. 
From this stage forward, we assume that we already have valid data. We also subset the data to get the wages of high school dropouts. We then make these three data sets and the cleaning workflow documentation publicly available through an R data container package called `yowie`. A visualisation of these process is displayed in  Figure \ref{fig:flow-chart}.-->

(ref:flow-chart) The stages of data cleaning from the raw data to get three datasets contained in `r yowie`. "# of individuals" means the number of respondents included in each stage, while "# of observations" means the number of rows in the data. The color represents the stage of data cleaning in statistical value chain [@validate]. Pink, blue, and green represent the raw, input, and valid data, respectively.

```{r flow-chart-blind, fig.cap="(ref:flow-chart)", out.width="85%", eval = CENSOR}
```

```{r flow-chart, fig.cap="(ref:flow-chart)", out.width="85%", eval = !CENSOR}
```

# Comparison of refreshed with the original data {#compare}


```{r sw_wages}
```

```{r do_refreshed}
```

```{r compare-sw-do}
```



<!--AE comment: first sentence can be removed or rephrased. Next sentence includes the word wages too many times. Next sentence should say “dropouts” rather than “drop outs” to be consistent with the previous sentence. -->
The original set, containing wages of high school dropouts [@SingerJudithD2003Alda] from 1979 through to 1994, is available in the R package `brolgar`. To compare the refreshed data with the original a subset needs to be matched. There are numerous ways to do this, with the simplest being to extract the individuals based on their id being part of the original data, and restricting the longitudinal measurements to the same years. However, we decided to try to replicate the process, as suggested by the description of the original data. This would require first identifying individuals who dropped out of high school.

## Filtering: Determining who is a dropout

There is no explicit explanation of how the dropouts cohort is determined in the original data. Hence, we use the high school dropouts criteria from @nlsy79edu, which are:

1. An individual whose highest grade completed (`hgc`) is reported to be less than 12th grade, **or**
2. An individual whose highest grade completed (`hgc`) is reported to be at least 12th grade and have received a GED (`ged` is code to 2).

An additional criteria from @SingerJudithD2003Alda is to only include males aged between 14 and 17 years old in 1979. With this filtering, we obtained 670 individuals in the refreshed data compared to 888 individuals in the original data. To investigate the reason for the difference, individuals from the original and refreshed dataset were matched by id. This revealed several reasons for for the disparity:

1. 173 individuals were more than 17 years old in 1979. Thus, it looks like the description of the original data is not quite accurate, that there are people older than 17 in the subset. Our decision is to also include them in the refreshed data as the new data contains an age variable, so analyst could filter them later. 
2. 79 individuals were less than or equal to 17 years old in 1979. However, they were not captured in the refreshed data because: 
    i. 35 of them completed at least 12th grade with a diploma instead of GED (`ged` variable is coded to 1). This suggests that they are not dropouts, and so we excluded them from the refreshed data. 
    ii. The information about `ged` is missing in 38 individuals. We decided to include them in the refreshed data. 
    iii. 3 individuals have both diploma and GED (`ged` is coded to 3). These were kept in the refreshed data. 
    iv. 12 individuals do not exist in `wages` data because they were participated in less than 3 rounds of survey. 

The filtering was re-applied using these decisions, resulting in a refreshed dropout subset containing 863 individuals. 

<!--AE comment: what does the natural log have to do with the y-axis?-->
<!--AE comment: For Figure 7, why did you choose to show the entire dataset here? It would be easier to make a comparison if the plot was cut off at 1994 on the x-axis.-->

```{r compare-xp-sw, fig.cap = "Density plot comparing the calculated work experience in the refreshed data, up to 1994, with that of the original data for male dropouts. Experience is shown on a square root scale to reduce the skewness. The highest concentration of observations is along the x=y axis, which means that most observations at most time points are similar.", out.width = "70%", eval=FALSE}
```

```{r plotting-sw-do, fig.cap = "Comparison of original textbook example (A) with refreshed data (B). The original data was inflation-adjusted to 1990 prices and the individual's time of collection was converted to a length of experience in the workforce, which makes it difficult to precisely compare the two sets.", fig.width = 9, fig.height = 5, out.width = "100%", cache = FALSE, eval=FALSE}
```

## Summaries of original with refreshed dropouts data

Because the original data does not have the year of collection, it is not possible to directly merge the two subsets. Merging longitudinal data requires both the key (`id`) and the index (ideally survey year). In the original data the experience variable is the time index, and it was not possible to exactly match this for the refreshed data. Thus, comparisons of the two sets has to be conducted in a two sample fashion rather than as a matched sample. 

Figure \ref{fig:compare-subsets} contains summaries of corresponding variables in the two subsets.

```{r compare-subsets, fig.cap = "Comparison of original textbook example with refreshed data: (A) highest grade completed, (B) experience and (C) log wages", fig.width = 9, fig.height = 7, out.width = "100%", cache = FALSE}
```


## The takeaways {#takeaways}

There are two aspects of the original data that we cannot replicate. The first is that the calculation of the work experience is not clearly articulated. @SingerJudithD2003Alda mention that the temporal variable is the years of experience since the first day of work. However, this exact same variable is not explicitly available in the database. From the NLSY79 topical guide [@nlsy79guide], we find that several variables are tagged as work experience-related variables. One of them is the weeks of worked since the last interview. This is used to calculate the variable. It produces a highly correlated results as shown in Figure \ref{fig:compare-xp-sw}. 

Secondly, in the original dataset, wages were inflation-adjusted to 1990 prices. This is not done for the refreshed data because we plan to keep refreshing it as the data added to and released from the survey. Instead we have provided a function in the R package, `r yowie`, for users to conduct the inflation adjustment when they are ready to analyse the data.  

```{r compare-xp-to-yrworkforce, fig.cap = "The association between the lenght of time in the workforce and the work experience. Generally, the longer someone were in the workforce, the higher the work experience. However, some of the respondents have much lower working experience compared to their duration in the workforce. This is possible when someone ", eval=FALSE}
```

<!--AE comment: “The treatment of unlikely wages differ in the refreshed data.” I think this means “The treatment of anomalous wages differs between the original and refreshed data sets.” Then you say “We opted to use the weights from a robust linear regression to determine what should be set as missing value as described in Section 3.2.1.” I don’t think you were setting missing values though, were you? It was used to determine which values should be imputed, correct? Either way, please clarify.-->
It is important to note that the treatment of unlikely wages differs in the refreshed data. In the original data by @SingerJudithD2003Alda, wages greater than $75 are set to be missing. However, this value is too low to be set as the maximum threshold, and it doesn't take into account temporal neighbors for an individual. We opted to use the weights from a robust linear regression to determine what should be regarded as extreme and imputed them with their predicted values as as described in Section \@ref(censor).

Figure \ref{fig:plotting-sw-do} shows a comparison of the two sets. (A direct ID matching is not possible.) There are 888 individuals in the original and 1,188 individuals in the refreshed data. This suggests some individuals were removed in the original data.
In addition, in the original set the racial breakdown was 246 Black, 204 Hispanic and 438 White participants, while in the refreshed data there are 346 Black, 219 Hispanic, and 623 White participants, so the proportions have not been exactly reproduced. On education, in the refreshed data there are very few individuals with less than a 12th grade education, which is different from the original. <!--AE comment: How many individuals up to 8th grade are in the refreshed dataset? What are plausible reasons for these differences?--> In the original data there were 366 individuals with up to 8th grade and 522 9th-12th grade, as compared to 967 with 12th grade in the refreshed data. 

```{r summaries, eval=FALSE}
```

<!-- Hence, in this section, we will compare how close the `wages_hs_do`, henceforth refreshed data, to the textbook data. It is also worth noting that the textbook data is reused from @MurnaneRichardJ1999DMDB’s paper. Hence, it is not directly extracted from the NLSY79 database.  @SingerJudithD2003Alda do not state the time frame covered by the data. However, from @MurnaneRichardJ1999DMDB’s paper, we find that the textbook data cover the survey period from 1979-1994. Hence, for comparison purposes, we filter the refreshed data only until 1994. 

In the absence of highs chool dropouts criteria in the textbook data, we create a clearer criteria of high school dropouts as mentioned in Section \@ref(#target). Consequently, we do not have the same ID of high-school dropouts as in the textbook data. The textbook data has `r nrow(sw_id)` IDs included, while the refreshed data has `r nrow(do_id)` IDs. Furthermore, there are only `r nrow(sw_do)` IDs included both in the textbook and the refreshed data. After observing @MurnaneRichardJ1999DMDB’s paper, it is mentioned that the data is randomly drawn from the low income subsample of the NLSY. This is probably the reason why, even using some criteria, we cannot match the dropouts in the textbook and the refreshed data.

Further, the temporal variable used in the textbook data is experience, instead of year. The only explanation we found regarding this variable is that it is derived from the years of IDs’ experience since their first job. @SingerJudithD2003Alda stated that this variable reflects the specific moment in each ID labor force history associated with each wage observation. 
Since it is not clearly articulated, we decide to keep the temporal variable in the refreshed data as year. Accordingly, in this comparison, we only compare the same ID but not the same temporal variable. 

Regarding the wages, the textbook data express the wages as inflation adjusted with 1990 dollars as constant [@SingerJudithD2003Alda]. However, it is not stated how exactly the wages are adjusted. Note that in the refreshed data we publish in `yowie`, we do not adjust the data with inflation because the time frame covered ranged from 1979-2018. Hence, we allow flexibility to the data user to adjust, not adjust,  or adjust it with different base years. For comparison purposes, we adjust the wages with the average Consumer Price Index For All Urban Consumers (CPI-U) we got from @fed. -->



<!-- Figure \ref{fig:plotting-sw-do} shows the comparison between the textbook and the refreshed data. Even though it has different temporal variables and possibly different CPI indicators used in inflation adjustment, we can still capture some of the patterns in the refreshed data.

From this comparison, we learn that we cannot make an apple to apple comparison and produce the exact same data as the textbook due to the absence of clearly articulated data extraction and derivation process. Hence, the takeaway is that it is imperative to disclose how the data derived from the initial source to make data analysis reproducible. This is why in this paper, we show the practice of reproducible and responsible data cleaning workflow to make sure the longitudinal data from a continuous survey can be refreshed.-->


# Summary {#summary}

This paper has illustrated the steps and decisions made to take a particular open data set and make it a textbook data set, ready for the classroom or research. In the first stage, we showed the steps performed to get the data from the NLSY79 database. The data format was converted to tidy format, for more flexibility in cleaning and exploring. An initial data analysis was conducted to investigate and screen the quality of the data. We found and provided a fix for many anomalous observations in wages using a robust linear regression model. The refreshed data is compared with the original set using a variety of numerical summaries and graphics. The current subset is made available in a new R package, called `r yowie`.

The data cleaning process is documented and the code has been made available. These provide the opportunity to again refresh the textbook data as new data is published into the NLSY79 database.
Determining an appropriate robustness weight from which to threshold unusual observations was conducted using a `shiny`  [@shiny] app, and the choices used in the refreshed data are documented. 

<!--AE comment: The bulleted difficulties in Section 5 are a bit jarring. Make them parallel (i.e. every bullet should start with a verb -ing so it is determining, calculating, etc) or turn them into a paragraph. I liked the specificity of $30,000/hour but it would be better up in the section where you discuss the anomalous values.-->

Various difficulties were encountered in trying to refresh the data, which include: 

- determining which records should be downloaded from the database.
- calculating experience in the workforce requires comparing the date of first job with the first year the individual was recorded, both of which are available in the database. 
- treating the extreme values since there are many unusually high hourly wages, e.g. greater than $60,000 per hour.
- determining the dropouts subset as there is no explicit variable in the database recording high school dropout, which means we needed to compare the date of 12th grade with their GED status.
- matching ID's from the original data with those in the refreshed data, do refer to the same person based on the demographic information available.

Ultimately, the refreshed data is reasonably similar to the original, but unsatisfactorily far from it. The last step required would be to inflation-adjust wages. This is better to do with each wave of new data added, so that it is relative to the last date in the data. Our decision was to provide the raw wages, and include code to do the adjustment as part of the package. 

<!--AE comment: At the end of page 14, it would be good to explicitly say that if people don’t like your decisions, they can grab the code and adjust the parameters themselves! It’s implied, but should be made explicit. -->
Some readers may disagree with our decisions made to produce the refreshed textbook data and may have better insight than us in producing a more appropriate textbook data. We do not assert that we have produced the best textbook data, but rather we describe our journey to provide a reasonable textbook data set. All code and documentation are provided for transparency. Readers could use this to make different decisions, or provide suggestions on through package for better choices. Future updates of the `r yowie` package may contain additional variables, or filters of the full set, if it is deemed important. 

For the data providers, we recommend that a better validation system with clear rules applied at data entry, and that alternative output formats, such as a tidy format would help users make better use of their resource. The problem with many of the wages records is that there are implausible values, or confusion on how to record wages for multiple jobs. These values can be validated with simple checks at data entry. Providing an open data resource also is accompanied with the responsibility that the data, especially data that is as valuable as this, is reliable. Users need to be able to trust the data. 

Why is this exercise important for teachers and students? This work illustrates the steps in cleaning and processing data in the preparation for it to be a textbook data set. Choices made during the cleaning and processing can affect findings made with the data, and these should be transparent. Along with the textbook data, which is now provided as an R package, the documentation of the process provide some examples for teaching data cleaning, initial data analysis and exploratory data analysis. The refreshed textbook data provides a resource for teaching longitudinal data analysis.

The wages data provides a good opportunity to discuss the difference between statistics to use for public policy and statistics that relate to the individual. Public policy is based on models, yielding averages that might vary across strata. Modeling the wages relative to workforce experience, with demographic covariates we learn that there are significantly different patterns. That more education leads to increasingly higher wages, which is a satisfying result for educators. It means that education makes a difference in the wage experience, and that public policy that encourages education is a data-supported action. We would also learn, although not presented here, that race matters and that being black leads to lower wages. This is a disturbing finding because there is no rational for such a difference in a fair society. This would provide support for action in public policy to remove this overall average effect. It also provides an example for educators to explain the use of data to support public policy action.

On an individual level, one needs to know where am I in this data, and does this data relate to me. To do this, the individual profiles need to be explored. Pre-dominantly, we would learn that the variation from one individual to another is far more than the variation between demographic strata. For example, many individuals with lower educational attainment earn very high wages. From a statistics and data science educator perspective, more focus and more methodology for this type of statistics needs to be included in the curriculum.

The above interpretations of results from analyzing the wages data, rely on trusting that the data provided is accurate and valid. The wages data is collected by a reputable organization, but we found that the data has obvious errors that should be corrected. This paper has illustrated procedures and guidelines to achieve valid data, and provides the code and details for it to be reproduced, and modified if deemed appropriate. 

Having trustworthy data is imperative for statistics and data science education. Whenever one uses a textbook data set that is perceived as relating to the students lives, there will be interpretations made. The wages data is an example of this. Students will take away the interpretations from whatever is taught with the data, that wages increase with experience, education, race. If one uses data examples that are synthetic, instilled with our own inherent prejudices (for e.g. gender and race), or data that has been poorly processed containing errors, we as educators are being irresponsible because the societal message taught to students may be flawed. This paper demonstrates the process to produce a trustworthy data set for teaching.

<!--this paper implies that data providers should design a database that is able to produce tidy data sets. A data provider should also check for data anomalies before the data publishing or at least provides a set of rules or threshold values. For example, in this case, is the threshold of reasonable wages. This will greatly support the data users to validate and set the same understanding of which data are considered outliers. Moreover, providing validation rules would facilitate any established data validation tool, such as `validate` [@validate] package. In this case, we cannot use this handy validation package due to the absence of validation rules. -->


# Acknowledgements 

We would like to thank Aarathy Babu for the insight and discussion during the writing of this paper. 

The entire analysis is conducted using `R` [@R] in RStudio IDE using these packages: `tidyverse` [@tidyverse], `ggplot2` [@ggplot2], `dplyr` [@dplyr], `readr` [@readr], `tidyr` [@tidyr], `stringr` [@stringr], `purrr` [@purrr], `brolgar` [@brolgar], `patchwork` [@patchwork], `kableExtra` [@kableExtra], `MASS` [@mass], `janitor` [@janitor], and `tsibble` [@tsibble]. The paper was generated using `knitr` [@knitr] and `rmarkdown` [@rmarkdown]. 


# Supplementary Materials 


- **Codes**: R script to reproduce data tidying and cleaning is available in this [page](`r yowie_pkgdown`/articles/process-data.html).

- **R Package**:`r yowie` is a data container R package that contains 3 datasets, namely the high school mean hourly wage data, high school dropouts mean hourly wage data, and demographic data of the NLSY79 cohort. This package can be accessed [here](`r yowie_repo`).

- **shiny app**: An interactive `shiny` web app to visualise the effect of selecting different weight threshold for substituting the wages data to its predicted value from a fit of the robust linear regression model. This app can be accessed [here](`r yowie_shiny`) with the source code provided [here](`r yowie_repo`/tree/master/app).


# Data Availability Statement

The authors confirm that the data supporting the findings of this study are available within the supplementary materials.

# References
